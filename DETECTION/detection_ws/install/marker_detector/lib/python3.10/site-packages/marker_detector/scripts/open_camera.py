#!/usr/bin/env python3
import cv2, vmbpy as vmb, numpy as np, queue, time, threading
from .LensConnect_Controller import UsbConnect, ScanUsbWithLensInfo
from . import DefVal as DV, LensCtrl
import json
from std_msgs.msg import String as ROSString
from math import degrees, acos

# --------------- PAR√ÅMETROS GENERALES ----------------
WIDTH, HEIGHT        = 3840, 2160
EXPOSURE_TIME        = 10000      # ¬µs
ZOOM_STEP, ZOOM_MIN, ZOOM_MAX = 1000, 4111, 17911
current_zoom         = 4111
current_focus        = 2860       # valor inicial de foco

INTENSITY_MIN        = 250        # umbral en canal V para LED muy brillante
MIN_AREA             = 10000
ROI_MARGIN           = 500        # px extra alrededor del marcador
ROI_LOST             = 15         # frames sin verlo 3antes de reset ROI

# Estas variables se asignar√°n din√°micamente
target_area = None    # ‚Üê Din√°mico
AREA_MIN = None       # ‚Üê Din√°mico
AREA_MAX = None       # ‚Üê Din√°mico
AREA_TOLERANCE = 0.15 # ¬±25% de tolerancia

parent_node = None  # Para pasar el nodo de ROS si es necesario
# -----------------------------------------------------

LOOKUP_TABLE = {
    17911: 4500,
    16911: 4550,
    15911: 4480,
    14911: 4380,
    13911: 4230,
    12911: 4060,
    11911: 3900,
    10911: 3730,
    9911: 3580,
    8911: 3450
}

# -----------------------------------------------
# Variables globales para el manejo de hilos y estado

focus_thread = None
focus_lock = threading.Lock()
is_focusing = False
key_queue = queue.Queue(maxsize=1)
last_frame = None
last_mask = None
last_roi_box = None
is_okey = False
roi_active = False
best_focus_global = 0  # Para almacenar el mejor foco global    
best_score_global = 0  # Para almacenar el mejor score global

def _ang(v1, v2):
    """√Ångulo absoluto entre dos vectores en grados."""
    dot = np.dot(v1, v2)
    n1  = np.linalg.norm(v1)
    n2  = np.linalg.norm(v2)
    return degrees(acos(dot / (n1 * n2 + 1e-12)))

def is_rectangle(pts, ang_tol=10):
    """
    Comprueba si el pol√≠gono de 4 v√©rtices 'pts' (CW/CCW) es un rect√°ngulo
    casi ortogonal.  ang_tol: tolerancia para 0¬∞/90¬∞ en grados.
    """
    v = [pts[(i+1) % 4] - pts[i] for i in range(4)]
    # lados opuestos ‚âà paralelos
    if _ang(v[0], v[2]) > ang_tol * 2 or _ang(v[1], v[3]) > ang_tol * 2:
        return False
    # lados consecutivos ‚âà ortogonales
    for i in range(4):
        if abs(_ang(v[i], v[(i+1) % 4]) - 90) > ang_tol * 2:
            return False
    return True
# ----------------------------------------------------------------------------

#-----------------------------------------------
# 1. M√©trica h√≠brida de nitidez
# ----------------------------------------------------------------------


def focus_metric_quick(roi_gray_down):
    gx = cv2.Sobel(roi_gray_down, cv2.CV_64F, 1, 0, ksize=3)
    gy = cv2.Sobel(roi_gray_down, cv2.CV_64F, 0, 1, ksize=3)
    g  = (gx ** 2 + gy ** 2).sum()
    var_lap = cv2.Laplacian(roi_gray_down, cv2.CV_64F).var()
    return g * 0.7 + var_lap * 0.3

def eval_pos_quick(x, y, w, h, focus_pos, roi_factor=0.5, num_samples=1):
    # 1) Mover foco
    global last_frame
    LensCtrl.FocusMove(int(focus_pos))
    if num_samples == 1:
        time.sleep(0.03)
    else:
        time.sleep(0.2)
    # 2) Recortar ROI del √∫ltimo frame y convertir a gray
    frame = last_frame
    x0, y0, w0, h0 = int(x), int(y), int(w), int(h)
    sub_roi_color = frame[y0:y0+h0, x0:x0+w0]
    sub_gray = cv2.cvtColor(sub_roi_color, cv2.COLOR_BGR2GRAY)
    # 3) Downsamplear
    new_size = (int(sub_gray.shape[1]*roi_factor), int(sub_gray.shape[0]*roi_factor))
    if new_size[0] < 10 or new_size[1] < 10:
        roi_gray_down = sub_gray
    else:
        roi_gray_down = cv2.resize(sub_gray, new_size, interpolation=cv2.INTER_LINEAR)
    # 4) Calcular m√©trica num_samples veces
    total = 0.0
    for _ in range(num_samples):
        total += focus_metric_quick(roi_gray_down)
    return total / num_samples

# ----------------------------------------------------------------------
# 2. Scan + Refino multinivel r√°pido
# ----------------------------------------------------------------------
def smart_autofocus_quick(x, y, w, h,
                         f_min=2739, f_max=5159,
                         scan_step=200,
                         levels=(20, 5, 1),
                         roi_factor=0.5):
    print(f"üîç Iniciando enfoque r√°pido: F {f_min}‚Äì{f_max}, step {scan_step}")
    scan_positions = list(range(f_min, f_max+1, scan_step))
    best_f, best_s = scan_positions[0], -1.0

    for index, p in enumerate(scan_positions):
        if index < 2 or index >= len(scan_positions) - 2:
            print(f"üîç Ignorando posici√≥n {p} (fuera de rango)")
            continue
        
        s = eval_pos_quick(x, y, w, h, p, roi_factor=roi_factor, num_samples=4)
        print(f"[Scan] F={p}  S={s}")
        if s > best_s:
            best_f, best_s = p, s


    for radius in levels:
        low  = max(f_min, best_f - radius)
        high = min(f_max, best_f + radius)
        step_ref = max(radius // 2, 1)
        for p in range(low, high+1, step_ref):
            s = eval_pos_quick(x, y, w, h, p, roi_factor=roi_factor, num_samples=1)
            if s > best_s:
                best_f, best_s = p, s
                print(f" ‚Ü≥ Mejorado ‚Üí F={p}  S={s:.0f}  (r={radius})")

    print(f"‚úÖ Focus √≥ptimo = {best_f}, score={best_s:.0f}")
    return best_f, best_s

# ----------------------------------------------------------------------
# 3. AUTOZOOM + AUTOFOCO
# ----------------------------------------------------------------------
def autofocus_and_zoom():
    global last_frame, last_mask, is_focusing, current_zoom
    global is_okey, roi_active, last_roi_box, target_area, AREA_MIN, AREA_MAX, best_focus_global, best_score_global, current_focus

    if is_focusing or last_frame is None:
        return
    is_focusing = True
    try:
        if not roi_active:
            print("‚ùå No hay ROI activa o no se ha detectado un marcador.")
            return

        cnts, _ = cv2.findContours(last_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        x0, y0, w0, h0 = cv2.boundingRect(max(cnts, key=cv2.contourArea))
        last_roi_box = (x0, y0, w0, h0)

        # 1) Zoom al m√°ximo
        LensCtrl.ZoomMove(ZOOM_MAX)
        current_zoom = ZOOM_MAX
        time.sleep(0.05)

        # 2) Enfoque r√°pido
        #best_focus, best_score = smart_autofocus_quick(x0, y0, w0, h0,
        #                                   f_min=2739, f_max=5159,
        #                                   scan_step=240, levels=(40,20,5, 1),
        #                                   roi_factor=0.5)
        best_focus , best_score  = 4500, 0.0
        best_focus_global = best_focus
        best_score_global = best_score
        LensCtrl.FocusMove(best_focus)
        print(f"üèÅ AutoFoco finalizado ‚Üí Zoom={current_zoom}, Focus={best_focus}")
        current_focus = best_focus

        # ‚Üê Tras el primer autofocus, fijamos TARGET_AREA si a√∫n no existe
        if target_area is None:
            cnts2, _ = cv2.findContours(last_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            x1, y1, w_rect, h_rect = cv2.boundingRect(max(cnts2, key=cv2.contourArea))
            primera_area = w_rect * h_rect
            target_area = float(primera_area)
            AREA_MIN = int(target_area * (1.0 - AREA_TOLERANCE))
            AREA_MAX = int(target_area * (1.0 + AREA_TOLERANCE))
            print(f"üéØ √Årea objetivo fijada din√°micamente: {target_area:.0f}px")
            print(f"   ‚Üí Rango de √°rea: [{AREA_MIN}, {AREA_MAX}]")

        is_okey = True

    finally:
        is_focusing = False

# ----------------------------------------------------------------------
# 4. Refino local de foco si hace falta
# ----------------------------------------------------------------------

def refine_focus_range(x, y, w, h, current_focus,
                       delta=20, roi_factor=0.5):
    """
    Busca en todo el rango [current_focus - delta, current_focus + delta]
    cu√°l posici√≥n da mejor score de nitidez (eval_pos_quick).
    Retorna esa posici√≥n de foco.
    """
    global best_focus_global, best_score_global

    # 2) Para compararlas, medimos tambi√©n el score en current_focus (si no coincide con best_focus_global)
    cf = int(current_focus)
    score_cf = best_score_global

    # Empezamos con la mejor posici√≥n conocida y su score:
    best_f = best_focus_global if best_focus_global is not None else cf
    best_s = best_score_global if best_focus_global is not None else score_cf

    # 3) Definimos los l√≠mites del rango (evitamos negativos o pasarnos del m√°ximo razonable)
    low  = max(cf - delta, 0)
    high = min(cf + delta, 50000)  # asumiendo 0..50000 como rango total de foco

    scan_positions = list(range(low, high+1, 10))

    # 4) Escaneo ‚Äúbruto‚Äù en todo ese rango
    for p in scan_positions:
        if p == best_f:
            continue
        print(f"üîç Evaluando foco {p}...")
        s = eval_pos_quick(x, y, w, h, p,
                           roi_factor=roi_factor,
                           num_samples=1)
        if s > best_s:
            best_s = s
            best_f = p

    # 5) Actualizamos la referencia global
    best_focus_global = best_f
    best_score_global = best_s

    print(f"   ‚Ü≥ B√∫squeda en rango [{low}..{high}]: mejor_focus={best_f}, score={best_s:.0f}")
    return best_f

def connect_lens(idx=0):
    ScanUsbWithLensInfo()
    if UsbConnect(idx) != DV.RET_SUCCESS:
        print("‚ùå LensConnect no disponible"); return None
    for init, move, val in [(LensCtrl.ZoomInit,  LensCtrl.ZoomMove,  4111),
                            (LensCtrl.FocusInit, LensCtrl.FocusMove, 2860),
                            (LensCtrl.IrisInit,  LensCtrl.IrisMove,     0)]:
        init(); move(val)
    print("üîå LensConnect listo"); return True

def frame_handler(cam, stream, frame):
    if not frame_q.full():
        frame_q.put(frame)
    cam.queue_frame(frame)

def keyboard_zoom_worker():
    global current_zoom
    while True:
        try:
            key = key_q.get(timeout=0.1)
        except queue.Empty:
            continue
        if key == 82:    # Flecha ‚Üë
            current_zoom = min(current_zoom + ZOOM_STEP, ZOOM_MAX)
            LensCtrl.ZoomMove(current_zoom)
            print(f"üîç Zoom={current_zoom}")
        elif key == 84:  # Flecha ‚Üì
            current_zoom = max(current_zoom - ZOOM_STEP, ZOOM_MIN)
            LensCtrl.ZoomMove(current_zoom)
            print(f"üîç Zoom={current_zoom}")

def has_two_parallel_pairs(box) -> bool:
    segs   = np.roll(box, -1, axis=0) - box
    angles = np.round((np.degrees(np.arctan2(segs[:,1], segs[:,0])) % 180) / 10) * 10
    _, counts = np.unique(angles, return_counts=True)
    return np.sum(counts >= 2) >= 2

# ----------------------------------------------------------------------
# 5. FUNCION PRINCIPAL
# ----------------------------------------------------------------------
def main():
    # Declaramos globals PARA EVITAR NameError
    global frame_q, key_q, last_frame, roi_active, last_mask
    global current_zoom, last_roi_box, target_area, AREA_MIN, AREA_MAX, parent_node

    frame_q, key_q = queue.Queue(30), queue.Queue(1)
    frame_skip = 0

    if connect_lens() is None:
        return
    cv2.setUseOptimized(True)

    with vmb.VmbSystem.get_instance() as vim:
        cam = vim.get_all_cameras()[0]
        with cam:
            cam.get_feature_by_name("PixelFormat").set(vmb.PixelFormat.BayerRG8)
            width = cam.get_feature_by_name("Width")
            height = cam.get_feature_by_name("Height")
            offsetX = cam.get_feature_by_name("OffsetX")
            offsetY = cam.get_feature_by_name("OffsetY")

            width.set(WIDTH)
            height.set(HEIGHT)
            offsetX.set((4512 - WIDTH)//2)
            offsetY.set((4512 - HEIGHT)//2)

            print(f"‚úÖ Resoluci√≥n: {width.get()}x{height.get()} "
                  f"(OffsetX={offsetX.get()}, OffsetY={offsetY.get()})")

            cam.get_feature_by_name("ExposureAuto").set("Off")
            cam.get_feature_by_name("ExposureTime").set(EXPOSURE_TIME)
            cam.get_feature_by_name("GainAuto").set("Off")
            cam.get_feature_by_name("Gain").set(0.0)
            cam.get_feature_by_name("IntensityControllerTarget").set(50.0)
            cam.get_feature_by_name("Gamma").set(1.0)
            cam.get_feature_by_name("BalanceWhiteAuto").set("Off")
            cam.get_feature_by_name("BalanceRatioSelector").set("Red")
            cam.get_feature_by_name("BalanceRatio").set(2.87)
            cam.get_feature_by_name("BalanceRatioSelector").set("Blue")
            cam.get_feature_by_name("BalanceRatio").set(2.40)

            cv2.namedWindow("Vista", cv2.WINDOW_NORMAL)
            cv2.namedWindow("Mask", cv2.WINDOW_NORMAL)
            cam.start_streaming(handler=frame_handler)

            rx0 = ry0 = rx1 = ry1 = lost = 0

            threading.Thread(target=keyboard_zoom_worker, daemon=True).start()
            while True:
                try:
                    frame = frame_q.get(timeout=1.0)
                except queue.Empty:
                    continue

                h, w = frame.get_height(), frame.get_width()
                bayer = np.frombuffer(frame.get_buffer(), np.uint8).reshape(h, w)
                full_disp = cv2.cvtColor(bayer, cv2.COLOR_BAYER_RG2RGB)
                last_frame = full_disp.copy()

                # Seleccionar ROI o imagen completa
                if roi_active and rx1 > rx0 and ry1 > ry0:
                    sub = full_disp[ry0:ry1, rx0:rx1]
                    offX, offY = rx0, ry0
                    if sub.size == 0:
                        sub, offX, offY, roi_active = full_disp, 0, 0, False
                        rx0, ry0, rx1, ry1 = 0, 0, w, h
                else:
                    sub, offX, offY, roi_active = full_disp, 0, 0, False
                    rx0, ry0, rx1, ry1 = 0, 0, w, h

                # -------- M√°scara por INTENSIDAD y cierre de huecos ---------------
                hsv = cv2.cvtColor(sub, cv2.COLOR_BGR2HSV)
                v_channel = hsv[:, :, 2]
                _, mask= cv2.threshold(v_channel, INTENSITY_MIN, 255, cv2.THRESH_BINARY)

                # Cerrar huecos grandes
                kernel_cerrar = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
                mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_cerrar)


                # Bordes y un poco de cierre otra vez
                kernel_edge = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
                mask_edges = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, kernel_edge)
                mask_edges = cv2.morphologyEx(mask_edges, cv2.MORPH_CLOSE, kernel_cerrar)

                # Dilataci√≥n ligera para cerrar discontinuidades
                mask_final = cv2.dilate(mask_edges,
                                    cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)),
                                    iterations=1)

                last_mask = mask_final.copy()
                cv2.imshow("Mask", cv2.resize(mask_final, (400, 400)))

                # -------- contornos & validaci√≥n geom√©trica --------
                cnts, _ = cv2.findContours(mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

                # Calculamos √°rea m√≠nima din√°mica seg√∫n zoom
                min_area_dynamic = int(MIN_AREA * (current_zoom / ZOOM_MIN) ** 2)

                mejor_score = -1.0
                mejor_box_global = None
                mejor_area = 0.0

                EPS = 1e-6 

                for c in cnts:
                    area_c = cv2.contourArea(c)
                    if area_c < min_area_dynamic:
                        print(f"üîç Contorno descartado por √°rea peque√±a: {area_c:.0f} < {min_area_dynamic}")
                        continue

                    # Dibujo en azul de cada contorno ‚Äúcandidato‚Äù por tama√±o
                    cv2.drawContours(full_disp, [c + np.array([offX, offY])], -1, (255, 0, 0), 2)

                    # Ajustamos rect√°ngulo m√≠nimo
                    rect = cv2.minAreaRect(c)
                    (cx, cy), (rw, rh), angle = rect

                    # Ajustamos rect√°ngulo m√≠nimo
                    rect = cv2.minAreaRect(c)
                    (cx, cy), (rw, rh), angle = rect

                    # Filtramos tama√±os peque√±os
                    if rw < 30 or rh < 30:
                        cv2.polylines(full_disp,
                      [cv2.boxPoints(rect).astype(int) + np.array([offX, offY])],
                      True, (0, 165, 255), 2)
                        print(f"üîç Contorno peque√±o: {rw}x{rh} (√°rea={area_c})")
                        continue
                    
                    aspect_ratio = max(rw, rh) / (min(rw, rh) + 1e-6)
                    if aspect_ratio > 1.5 or aspect_ratio < 0.7:
                        cv2.polylines(
                            full_disp,
                            [cv2.boxPoints(rect).astype(int) + np.array([offX, offY])],
                            True,
                            (0, 0, 255),
                            2
                        )
                        cv2.putText(
                            full_disp,
                            f"AR={aspect_ratio:.2f}",
                            (int(cx + offX), int(cy + offY)),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.7,
                            (0, 0, 255),
                            2
                        )
                        print(f"üîç Aspect ratio no v√°lido: {aspect_ratio:.2f} (rw={rw}, rh={rh})")
                        continue


                    # Obtenemos los 4 puntos del rect√°ngulo
                    box = cv2.boxPoints(rect).astype(int)

                    # Comprobamos que haya dos pares de lados paralelos
                    if not has_two_parallel_pairs(box):
                        cv2.polylines(full_disp,
                                      [box + np.array([offX, offY])],
                                      True, (255, 0, 255), 2)
                        print("üîç No hay dos pares de lados paralelos, descartando contorno")
                        continue

                            # 1) Cu√°n cerca est√° el aspecto a 1:1
                    score = area_c / (1.0 + abs(aspect_ratio - 1.0))
                    if score > mejor_score:
                        mejor_score = score
                        mejor_box_global = box + np.array([offX, offY])
                        mejor_area = area_c

                # Si encontramos un cuadrado v√°lido, lo dibujamos
                if mejor_box_global is not None:
                    # Polil√≠nea verde gruesa
                    cv2.polylines(full_disp, [mejor_box_global], True, (0, 255, 0), 3)

                    # Puntos en los v√©rtices
                    for (px, py) in mejor_box_global:
                        cv2.circle(full_disp, (px, py), 6, (0, 255, 0), -1)

                    # Guardamos ROI y margen
                    x0, y0, w0, h0 = cv2.boundingRect(mejor_box_global)
                    last_roi_box = (x0, y0, w0, h0)

                    # Publicamos la informaci√≥n de detecci√≥n
                    center_x = x0 + w0 // 2
                    center_y = y0 + h0 // 2

                    detection_info = {
                        "height": h,
                        "width": w,
                        "pos_x": center_x,
                        "pos_y": center_y
                    }

                    json_msg = json.dumps(detection_info)
                    msg = ROSString()
                    msg.data = json_msg
                    parent_node.publisher.publish(msg)
                    parent_node.get_logger().info(f"Published (adjusted ROI): {json_msg}")


                    rx0 = max(0, mejor_box_global[:, 0].min() - ROI_MARGIN)
                    ry0 = max(0, mejor_box_global[:, 1].min() - ROI_MARGIN)
                    rx1 = min(w, mejor_box_global[:, 0].max() + ROI_MARGIN)
                    ry1 = min(h, mejor_box_global[:, 1].max() + ROI_MARGIN)
                    roi_active = True

                    # ‚îÄ‚îÄ Asignar TARGET_AREA tras primer autofocus ‚îÄ‚îÄ
                    if is_okey and target_area is None:
                        cnts2, _ = cv2.findContours(last_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        x1, y1, w_rect, h_rect = cv2.boundingRect(max(cnts2, key=cv2.contourArea))
                        primera_area = w_rect * h_rect
                        target_area = float(primera_area)
                        AREA_MIN = int(target_area * (1.0 - AREA_TOLERANCE))
                        AREA_MAX = int(target_area * (1.0 + AREA_TOLERANCE))
                        print(f"üéØ √Årea objetivo asignada din√°micamente: {target_area:.0f}px")
                        print(f"   ‚Üí Rango de √°rea: [{AREA_MIN}, {AREA_MAX}]")

                    if is_okey and target_area is not None and not is_focusing:
                        area_actual = mejor_area
                        print(f"üîç √Årea actual del marcador: {area_actual:.0f}px")
                        if area_actual > AREA_MAX:
                            def thread_job_large():
                                global is_focusing, current_zoom, last_roi_box
                                global target_area, AREA_MIN, AREA_MAX

                                print(f"üîé Marcador grande ({area_actual:.0f}px) ‚Üí Ajuste iterativo de zoom/foco")
                                is_focusing = True

                                # 1) Si el cambio es demasiado brusco, abortamos:
                                ratio = area_actual / target_area
                                if ratio > 2.0 or ratio < 0.5:
                                    print(f"   ‚ö†Ô∏è Cambio muy brusco (ratio={ratio:.2f}), se ignora ajuste")
                                    is_focusing = False
                                    return

                                new_zoom = max(ZOOM_MIN, current_zoom - ZOOM_STEP)
                                print(f"üîé Marcador grande ({area_actual:.0f}px) ‚Üí Zoom proporcional a {new_zoom}")
                                current_zoom = new_zoom
                                LensCtrl.ZoomMove(current_zoom)
                                time.sleep(0.1)

                                fx, fy, fw, fh = last_roi_box
                                final_focus = LOOKUP_TABLE.get(current_zoom)
                                LensCtrl.FocusMove(final_focus)
                                print(f"   ‚ï∞‚Üí Nuevo focus={final_focus}")

                                # 10) Reasignar target_area seg√∫n la √∫ltima ROI (fw√ófh)
                                nueva_area = fw * fh
                                target_area = float(nueva_area)
                                AREA_MIN = int(target_area * (1.0 - AREA_TOLERANCE))
                                AREA_MAX = int(target_area * (1.0 + AREA_TOLERANCE))
                                print(f"üéØ Nuevo target_area = {target_area:.0f}px ‚Üí rango [{AREA_MIN}, {AREA_MAX}]")

                                is_focusing = False

                            focus_thread = threading.Thread(target=thread_job_large, daemon=True)
                            focus_thread.start()

                        if area_actual < AREA_MIN:
                            def thread_job_small():
                                global is_focusing, current_zoom, last_roi_box
                                global target_area, AREA_MIN, AREA_MAX

                                print(f"üîé Marcador peque√±o ({area_actual:.0f}px) ‚Üí Ajuste iterativo de zoom/foco")
                                is_focusing = True
                                ratio = target_area / area_actual
                                if ratio > 3.0 or ratio < 0.2:
                                    print(f"   ‚ö†Ô∏è Cambio muy brusco (ratio={ratio:.2f}), se ignora ajuste")
                                    is_focusing = False
                                    return

                                new_zoom = min(ZOOM_MAX, current_zoom + ZOOM_STEP)
                                print(f"üîé Marcador peque√±o ({area_actual:.0f}px) ‚Üí Zoom proporcional a {new_zoom}")
                                current_zoom = new_zoom
                                LensCtrl.ZoomMove(current_zoom)
                                time.sleep(0.1)

                                fx, fy, fw, fh = last_roi_box
                                final_focus = LOOKUP_TABLE.get(current_zoom)
                                LensCtrl.FocusMove(final_focus)
                                print(f"   ‚ï∞‚Üí Nuevo focus={final_focus}")

                                nueva_area = fw * fh
                                target_area = float(nueva_area)
                                AREA_MIN = int(target_area * (1.0 - AREA_TOLERANCE))
                                AREA_MAX = int(target_area * (1.0 + AREA_TOLERANCE))
                                print(f"üéØ Nuevo target_area = {target_area:.0f}px ‚Üí rango [{AREA_MIN}, {AREA_MAX}]")

                                is_focusing = False

                            focus_thread = threading.Thread(target=thread_job_small, daemon=True)
                            focus_thread.start()



                else:
                    roi_active = False
                    rx0, ry0, rx1, ry1 = 0, 0, w, h

                if roi_active:
                    cv2.rectangle(full_disp, (rx0, ry0), (rx1, ry1), (255, 0, 255), 2)

                frame_skip += 1
                if frame_skip % 30 == 0 and not is_focusing and not is_okey:
                    def focus_job():
                        global is_focusing
                        if not is_focusing and not is_okey:
                            print("üü° Iniciando enfoque autom√°tico y ajuste de zoom...")
                            autofocus_and_zoom()
                    focus_thread = threading.Thread(target=focus_job)
                    focus_thread.start()

                cv2.imshow("Vista", cv2.resize(full_disp, (1280, 720)))

                key = cv2.waitKey(1) & 0xFF
                if key == 27:
                    break
                key_q.put(key)

            cam.stop_streaming()
            cv2.destroyAllWindows()

def start(node):
    global parent_node
    parent_node = node  # Guardamos el nodo de ROS para usarlo si es necesario
    print("üîå Iniciando c√°mara...")
    main()

if __name__=="__main__":
    main()
